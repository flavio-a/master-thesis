\chapter{Arbitrary domains}
In the previous chapter we presented some results about integer domains. In this one, we would like to explore how much of the previous results can be generalized to arbitrary domains.

In this chapter we assume a set $C$ of values and use as concrete domain $\pow(C)$. We also assume an under-approximation Galois insertion $\pow(C) (\alpha, id_A) A$, that is $\alpha \preceq \id_C$ and $A$ is closed by union (propositions \ref{ch2:th:under-gc-extensive-charact} and \ref{ch2:th:under-gc-union-closure}.
Moreover, we use the same symbol for both a function $f : C \rightarrow C$ and its additive extension $f: \pow(C) \rightarrow \pow(C)$.

\section{Non relational domains}
An important notion for abstract domains is that of being or not relational. Intuitively, a non relational domain can't capture relations between different variables. For instance, the product of interval domains (see example \ref{ch2:ex:intervals}) for each variable is non relational.
\begin{example}
	Consider the simple program fragment
	\begin{minted}{C}
		y = 5 - x;
		z = x + y;
	\end{minted}
	and assume at the beginning the variable \code{x} assumes values in the interval $[0, 5]$. An interval analysis on this fragment would find that \code{y} takes values in the interval $5 - [0, 5] = [0, 5]$, and then \code{z} is in the result of $[0, 5] + [0, 5]$, that in general is $[0, 10]$. However at the end of the program \code{z} is always $5$.
	The issue here is that the values of \code{x} and \code{y} aren't independent, so an operation between these two variables can't actually receive all possible inputs with \code{x} in $[0, 5]$ and \code{y} in $[0, 5]$, but only those that also satisfy the \textit{relation} \code{y = 5 - x}. However, the interval domain knows nothing about this relation since it abstracts each variable independently.
\end{example}
There exists extensions of the intervals domain that are relational, for instance octagons \cite{mine-octagons} and polyhedrons \cite{cousot-polyhedrons}. In general, non relational domains are less precise but also computationally less expensive.

The concept of non relational domain is frequently referred to in the literature, but not so often formalized. We stick to a slight variation of the one proposed in \cite{giacobazzi-analyzing-analyses}, section $5.2$.
Given a set of variables $\text{Vars}$ and, for each one of these variables $x$, a concrete domain $C_x$, a concrete domain for the set of variables is the power set of
\[
C = \prod\limits_{x \in \text{Vars}} C_x
\]
An element of the cartesian product $C$ is a function that maps each variable $x$ into a value in its domain $C_x$ (a tuple of elements, one for each variable $x$ and taken from $C_x$), so it's exactly one of the possible states a program that operates on the set of variables $\text{Vars}$ can be in. The power set of that product is hence a concrete domain whose elements are set of possible states of such a program.

\begin{definition}[Non relational domain]
	An abstract domain $A$ for the concrete domain $\pow(C)$ is \textit{non relational} if it can be decomposed as
	\[
	A = \prod\limits_{x \in \text{Vars}} A_x
	\]
	that is a product of one abstract domain for each variable, where for each variable $x$ there is a Galois connection $\pow(C_x) (\alpha_x, \gamma_x) A_x$ between the concrete domain for that variable and $A_x$, and the Galois connection $\pow(C) (\alpha, \gamma) A$ is defined by
	\begin{align*}
		\alpha(S) &= (\alpha_x(\pi_x(S)), \alpha_y(\pi_y(S)), \dots) \\
		\gamma(a) &= \gamma_x(a_x) \times \gamma_y(a_y) \times \dots
	\end{align*}
	where $\pi_x$ denotes the additive extension of the projection $C \rightarrow C_x$ and $a_x$ is the $x$-component of tuple $a \in \prod\limits_{x \in \text{Vars}} A_x$.
\end{definition}

A non relational abstract domain is a tuple of elements, one for each variable $x$, and describes the set of concrete states where each variable belongs to the values in it's abstract coordinate. The abstraction is performed on each variable independently, projecting all states in $S$ on that variable and then abstracting the resulting set. The concretization is performed on each variable independently, and then results are multiplied in all possible ways to get concrete values.
This separate handling of different variables prevent expressing relations. When abstracting, we lose all informations on possible relations since we project on each variable before abstracting. Conversely, when concretizing an abstract tuple, each element is concretized independently and hence the result is a Cartesian product of sets of possible values for each variable.

If we consider and under-approximation non relational domain, we have to take into account both the fact that abstract elements are concretized in Cartesian product of set of values for each variable, and the fact that the domain is closed under union. Unfortunately, these two properties are incompatible.
\begin{prop}\label{ch3:th:underapprox-non-rel}
	Let $\pow(C) (\alpha, \gamma) A$ be an under-approximating Galois connection, and assume $A$ is non relational. Then, for all but one variable (let it be $y$), the abstract domain $A_x$ is \textit{almost} trivial, that is it contains at most one value $a_x$ other than $\bot$:
	\[
	\forall x \in \text{Vars} \setminus \{ y \} \ .\ A_x = \{ a_x, \bot \}
	\]
\end{prop}
\begin{figure}[!ht]
	\centering{
		{
			\fontsize{11pt}{13pt}\selectfont
			\def\svgwidth{3.5in}
			\input{images/non-rel-proof.pdf_tex}
		}
		\caption{Intuition of the proof of proposition \ref{ch3:th:underapprox-non-rel}}
		\label{ch3:fig:rel-domain}
	}
\end{figure}
\begin{proof}
	For the sake of simplicity, let us assume that the Galois connections $\pow(C_x) (\alpha_x, \gamma_x) A_x$ for each variable $x$ are actually Galois insertions, and let us use the usual identification of $A_x$ and $\gamma(A_x) \subseteq \pow(C_x)$.
	Moreover, let us assume that $\text{Vars}$ only contains two variables; the proof generalizes straightforwardly to an arbitrary set of variables, but it clutters the notation a lot.

	By way of contradiction, suppose that for both variables $y$ and $z$ domains $A_y$ and $A_z$ contains more than one element other than $\bot$: let $S_y, S'_y \in A_y$ and $S_z, S'_z \in A_z$.

	Since $S_y \neq S'_y$, without loss of generality we can assume $S'_y \nsubseteq S_y$ (otherwise just swap their names), and let $T_y = S_y \cup S'_y$. By union closure of the abstract domain $A_y$ (proposition \ref{ch2:th:under-gc-union-closure}), $T_y \in A_y$. Moreover, since $S'_y$ is not a subset of $S_y$, $T_y$ is a strict superset of $S_y$, and $S_y \neq \emptyset$ by hypothesis:
	\[
	\emptyset \subset S_y \subset T_y
	\]
	The situation is described on the horizontal axis of figure \ref{ch3:fig:rel-domain}: the non empty set $S_y$ is a strict subset of $T_y$, and hence the difference of the two sets is non empty too.
	Analogously, we define $T_z = S_z \cup S'_z$ and get that $T_z \in A_z$ and
	\[
	\emptyset \subset S_z \subset T_z
	\]

	We now use union closure of the domain $A$ to get that
	\[
	S_y \times T_z \cup T_y \times S_z
	\]
	is in the abstract domain too. But this is not the product of two subsets of $C_y$ and $C_z$, as can be be quickly seen in figure \ref{ch3:fig:rel-domain}: the union is the red area, that clearly isn't a rectangle (a product of sets for $y$ and $z$).

	Formally, consider $v_y \in S_y$, $w_y \in T_y \setminus S_y$, $v_z \in S_z$ and $w_z \in T_z \setminus S_z$. We have that $(w_y, v_z) \in T_y \times S_z$ and $(v_y, w_z) \in S_y \times T_z$ but $(w_y, w_z) \notin S_y \times T_z \cup T_y \times S_z$ since it doesn't belong to neither of the two, so this can't be the product of two subsets of $C_y$ and $C_z$.
\end{proof}

Again this result is an abstract interpretation way to rephrase O'Hearn's sentence \cite{ohearn-incorrectness-logic} ``For incorrectness reasoning, you must remember information as you go along a path [...]".
The need to remember informations along a path implies exactly that the analysis can't forget which were the values of other variables that get each of the results, that is it can't forget relations between variables.

\section{Non emptyingness}
\todo{copy definitions and lemmas here?}
In the previous chapter we introduced the definition \ref{ch3:def:non-emptying} of non emptying function when talking about integers, but this notion is fully general with respect to the concrete domain: we already applied it to both the infinite set of integers $\setZ$ and the finite interval $[-N, N]$, so we want now to work with an arbitrary concrete domain $\pow(C)$.
We remark that also definition \ref{ch3:def:repr-with-set} of elements representable with a set and lemma \ref{ch3:th:f-non-repr-pair} are fully general and doesn't depend on the specific integer domain we used in the previous chapter, as well as lemma \ref{ch3:th:R-S-bound-integer-inf} if we assume $C$ to be infinite. Hence we start from these to build results independent of the concrete domain.

In our results for integers, we showed that an under-approximation abstract domain can't be non emptying for all functions in a given family (in that case, adding a constant). Now we would like to generalize those results, investigating which conditions \textit{on the family of functions} are sufficient to ensure that no abstract domain can be non emptying for all of them. The reason of this is that first we fix a function family, corresponding to a program, and then we look for a domain well suited to analyse the specific family (ie. program) at hand.

In the following sections, we present two impossibility results. They share the same general structure: we fix a function family $F$ with some properties, assume that they are all non emptying in the abstract domain and that $R$ isn't empty. We need this last assumption in order to use lemma \ref{ch3:th:f-non-repr-pair}: if $R$ is empty we can't prove $f(\bar{c}) \in R$.
Both results require the function family to satisfy a specific condition: that of being highly surjective.

\begin{definition}[Highly surjective function family]\label{ch4:def:highly-onto-func-family}
	Given a family $F$ of functions from $C$ in itself and an element $c \in C$, let
	\[
	P(c) = \{ d \in C \svert \exists f_d \in F .\ f_d(d) = c \}
	\]
	be the set of \textit{preimages of $c$}, elements of $C$ for which there exists a function in $F$ that maps that element to $c$.

	We say that the family $F$ is \textit{highly surjective} (or \textit{highly onto}) if $P(c)$ is infinite for any possible choice of $c \in C$.
\end{definition}

Clearly the family of functions that add a constant is highly surjective, and actually satisfies a stronger property: for any $c$ \textit{all} possible choices of $d$ (that are infinitely many) have a function $f_d(x) = x + c - d$ such that $f_d(d) = c$, that is $P(c) = \setZ$. We used this property in the proof in order to apply lemma \ref{ch3:th:f-non-repr-pair}: we took an element $\bar{n}$ not representable with $n_0$ and used said function in order to get $f(\bar{n}) = n_0 \in R$, hence being able to apply the lemma to get $f(n_0) \in R$. The point is that at the beginning the only representable element we know of is $n_0$, so our only hope to show $f(\bar{n}) \in R$ is to show that $f(\bar{n}) = n_0$, hence we need a function that maps $\bar{n}$ in $n_0$.

The next two sections present the two impossibility results, the following discuss limits of approaches based on non emptyingness and the last one of the chapter contains considerations on finite domains.

\section{Local result}
This first result is somehow more ``local", in the sense that we require each function in $F$ to satisfy some properties independently from other functions in $F$. In its basic formulation, we just require each function in $F$ to be injective.

\begin{theorem}\label{ch4:th:non-empt-res-local-basic}
	Let $F$ be a family of functions from $C$ in itself such that
	\begin{itemize}
		\item $F$ is highly surjective
		\item all functions $f \in F$ are injective
	\end{itemize}
	Assume also that $R$ isn't empty. Then $A$ can't be non emptying for all $f \in F$.
\end{theorem}
The proof of this theorem is quite involved. It starts from $c_0 \in R$, that exists because $R$ is not empty, and iteratively creates a sequence $c_n$ of representable elements. This yields a contradiction since $R$ should be finite.

\begin{figure*}[ht]
	\centering
	\begin{tikzpicture}
		\tikzset{vertex/.style = {shape=circle,fill,inner sep=1pt}}
		\tikzset{func/.style = {->,> = latex'}}

		% vertices \bar{c}
		\node[vertex,label=left:$\bar{c}$] (bc1) at (0,1){};
		\node[vertex,label=left:$\bar{c}$] (bc2) at (0,0.5){};
		\node at (0,0.1){$\vdots$};
		\node[vertex,label=left:$\bar{c}$] (bc3) at (0,-0.5){};
		\node[vertex,label=left:$\bar{c}$] (bc4) at (0,-1){};

		% vertices cn
		\node[vertex,label=above:$c_0$] (c0) at (1,0){};
		\node[vertex,label=above:$c_1$] (c1) at (2,0){};
		\node[vertex,label=above:$c_2$] (c2) at (3,0){};
		\node (c2dots) at (4,0){$\dots$};
		\node[vertex,label=above:$c_n$] (cn) at (5,0){};
		\node (cndots) at (6,0){$\dots$};

		%edges \bar{c} -> c_0
		\draw[func] (bc1) to (c0);
		\draw[func] (bc2) to (c0);
		\draw[func] (bc3) to (c0);
		\draw[func] (bc4) to (c0);
		% edge c0 -> c1 -> ...
		\draw[func] (c0) to (c1);
		\draw[func] (c1) to (c2);
		\draw[func] (c2) to (c2dots);
		\draw[func] (c2dots) to (cn);
		\draw[func] (cn) to (cndots);
	\end{tikzpicture}
	\caption{Graphical representation of the ``final" $f$}
	\label{ch4:fig:final-f-sketch}
\end{figure*}

The main idea is to pick a suitable $f$ in $F$ and define the sequence as the iterates $c_{n+1} = f(c_n)$. This function is sketched in figure \ref{ch4:fig:final-f-sketch}. The initial set of $\bar{c}$ mapped to $c_0$ is required to be able to apply lemma \ref{ch3:th:f-non-repr-pair} to all pairs $\{ \bar{c}, c_n \}$ and get that $c_{n+1} = f(c_n)$ is representable, since $f(\bar{c}) = c_0 \in R$.
The issue with this idea is that we don't have enough information on the sequence to pick such an $f$ at the beginning, so we actually bring along a list of candidate $f$ that all coincides on a prefix of the sequence. At step $n$, we pick a new element of the sequence among the possible images of $c_{n-1}$ through all candidate $f$ we have at that point, and discard all those functions that doesn't match the choice.

Actually, instead of directly consider functions, we represent them with elements $\bar{c}$ of $C$. Each element represent a function $f_{\bar{c}}$ that satisfies $f_{\bar{c}}(\bar{c}) = c_0$. Note that this function exists for ``enough" (that is, infinitely many) $\bar{c}$ because of the high surjectivity hypothesis. We call $E_n$ the set of $\bar{c}$ that represent functions that are ``valid" for the prefix up to $n$, ie. they map $c_{i}$ to $c_{i+1}$ for $0 \le i \le n - 1$. The core of the proof is an induction that proves that $E_n$ always contains infinitely many elements and that the newly chosen $c_n$ is different from all the others.

\begin{proof}
	Assume by contradiction that $A$ is non emptying for all $f \in F$. By hypothesis, $R$ isn't empty and thus we can take a $c_0 \in R$. We then construct recursively a sequence of representable elements $c_n$.

	Given an element $c \in C$, let
	\[
	NR(c) = C \setminus R(c) = \{ \bar{c} \in C \svert \{ c, \bar{c} \} \text{ is not representable} \}
	\]
	be the set of elements that are \textit{not} representable with it.

	Since $F$ is an highly surjective family, for an infinite amount of $\bar{c}$ there exists $f_{\bar{c}}$ such that $f_{\bar{c}}(\bar{c}) = c_0$.

	To ease presentation, we define here $E_n$, a set of element of $C$ that depends on the sequence $c_n$ we'll construct in the proof. Do note that the definition of $E_n$ only depends on elements of the sequence up to $c_n$.
	\begin{align*}
		E_n = \{\bar{c} \in C \svert & \forall\ 0 \le i \le n \ .\ \bar{c} \in NR(c_i), \\
		& f_{\bar{c}}(\bar{c}) = c_0, \\
		& \forall\ 0 \le i \le n - 1 \ .\ f_{\bar{c}}(c_i) = c_{i + 1} \}
	\end{align*}
	In the light of the introduction above, the first line is needed to apply lemma \ref{ch3:th:f-non-repr-pair} to the pair $\{ c_i, \bar{c} \}$ and get that $f_{\bar{c}}(c_i) = c_{i+1}$ is representable. The second one means that $\bar{c}$ actually represents $f_{\bar{c}}$, and the last is the requirement that $f_{\bar{c}}$ coincides on the prefix of the sequence up to $c_n$.

	We observe that the sequence $E_n$ can also be defined inductively by
	\begin{align*}
		E_0 &= \{ \bar{c} \in C \svert \bar{c} \in NR(c_0), f_{\bar{c}}(\bar{c}) = c_0 \} \\
		&= NR(c_0) \cap P(c_0)
	\end{align*}
	\begin{align*}
		E_{n+1} &= \{\ \bar{c} \in E_n \svert \bar{c} \in NR(c_{n+1}), f_{\bar{c}}(c_n) = c_{n+1} \} \\
		&= NR(c_{n+1}) \cap \{\ \bar{c} \in E_n \svert f_{\bar{c}}(c_n) = c_{n+1} \} \addtocounter{equation}{1}\tag{\theequation} \label{ch4:eq:En-relation}
	\end{align*}
	$E_0$ is the intersection of $NR(c_0)$ and the set of $\bar{c}$ for which there exists $f_{\bar{c}}$. Using lemma \ref{ch3:th:R-S-bound-integer-inf} to say $R(c_0)$ is finite and recalling that $P(c_0)$ is infinite (by high surjectivity), we observe that
	\begin{align*}
		E_0 = P(c_0) \cap NR(c_0) = P(c_0) \setminus (C \setminus NR(c_0)) = P(c_0) \setminus R(c_0)
	\end{align*}
	is infinite too.

	We then prove by induction on $n$ the following three statements: first $c_n$ is representable, ie. $c_n \in R$; second $E_n$ is infinite; third $c_n$ is different from all $c_i$ for $0 \le i \le n - 1$.
	We've already proved base case for $n = 0$: $c_0$ is representable by hypothesis, $E_0$ is infinite as shown above and the third condition is vacuous since there are no $0 \le i \le -1$.
	For the inductive step, assume the three hypothesis hold for $n$ and let us prove them for $n + 1$.
	Consider the set
	\[
	S = \{ f_{\bar{c}}(c_n) \svert \bar{c} \in E_n \}
	\]
	of candidate $c_{n+1}$.
	Since $c_n \in R$, $\bar{c} \in E_n \subseteq NR(c_n)$ and $f_{\bar{c}}(\bar{c}) = c_0 \in R$ (by inductive hypotheses) we can apply lemma \ref{ch3:th:f-non-repr-pair} to get $f_{\bar{c}}(c_n) \in R$ too, hence $S$ is a subset of $R$.
	Since $R$ is finite also $S$ must be, and by inductive hypothesis we know $E_n$ is infinite, so there must exists an element $c_{n+1}$ in $S$ such that an infinite amount of $\bar{c} \in E_n$ satisfies $f_{\bar{c}}(c_n) = c_{n+1}$. We observe that, as shown above, $c_{n+1} \in R$. Moreover we chose $c_{n+1}$ such that
	\[
	\{\ \bar{c} \in E_n \svert f_{\bar{c}}(c_n) = c_{n+1} \}
	\]
	is infinite, so we get
	\[
	\{\ \bar{c} \in E_n \svert f_{\bar{c}}(c_n) = c_{n+1} \} \cap NR(c_{n+1}) = \{\ \bar{c} \in E_n \svert f_{\bar{c}}(c_n) = c_{n+1} \} \setminus R(c_{n+1})
	\]
	is infinite too because $R(c_{n+1})$ is finite. But this, by equation \eqref{ch4:eq:En-relation} above, is exactly $E_{n+1}$.

	We only have to show that $c_{n+1} \neq c_i$ for all $0 \le i \le n$. Assume by contradiction that this is not the case: for some $0 \le j \le n$ it holds $c_{n+1} = c_j$, and let us distinguish two cases. If $j = 0$ we get $f_{\bar{c}}(c_n) = c_{n+1} = c_0 = f_{\bar{c}}(\bar{c})$, that would imply $c_n = \bar{c}$, but the former is representable and the latter is not. If otherwise $j > 0$ we get $f_{\bar{c}}(c_n) = c_{n+1} = c_j = f_{\bar{c}}(c_{j-1})$, that would imply $c_n = c_{j-1}$, that is not the case by inductive hypothesis. So $c_{n+1} \neq c_j$, and this concludes the inductive proof.

	By the induction above we have that all $c_n$, that are an infinite amount, are elements of $R$ and are all distinct. This yields the desired contradiction because $R$ is finite.
\end{proof}

Intuitively, if we were able to find the ``final" $f$ from the beginning, it would look like figure \ref{ch4:fig:final-f-sketch}: some $\bar{c}$, those for which that $f$ is $f_{\bar{c}}$, are mapped to $c_0$, and from there it just maps each $c_n$ to $c_{n+1}$. Do note that this is just an intuitive description: in fact, such an $f$ may not even exists (this correspond to the limit of $E_n$ being empty), but is indeed useful to visualize the proof.

A simple example of such a function family are constant sums over integers.
\begin{example}
	We take $C = \setZ$ and
	\[
	F = \{ \lambda x. x + n \svert n \in \setZ \}
	\]
	The family is highly surjective (actually $P(c) = \setZ$ for all $c$) and all these functions are injective, so it meets the hypothesis of the theorem.
\end{example}

Even though we've already proved that no abstract domain can be non emptying for all functions in this family $F$ in proposition \ref{ch3:th:ne-sum-nonexsistence-inf} in the previous chapter, it's important to note that this proof isn't a generalization of the proof of that proposition. In this proof, we iterate a single $f$ to build the entire sequence, while in that one we change the function every time, mapping the non representable $\bar{n}$ to the newly found representable $n_0 + t d$ to get that the image of $n_0$ through that function is representable too, as sketched in figure \ref{ch4:fig:ne-sum-inf-sketch}.

\begin{figure*}[ht]
	\centering
	\begin{tikzpicture}
		\tikzset{vertex/.style = {shape=circle,fill,inner sep=1pt}}
		\tikzset{func/.style = {->,> = latex'}}

		% nodes cn
		\node[label=above:$\bar{n}$] (bnt) at (0, 2){};
		\node (bnb) at (0, -2){};
		\draw (bnt) to (bnb);

		\node[label=above:$n_0$] (n0t) at (2, 2){};
		\node (n0b) at (2, -2){};
		\draw (n0t) -- (n0b);

		\node[label=above:$n_0+d$] (n1t) at (4, 2){};
		\node (n1b) at (4, -2){};
		\draw (n1t) -- (n1b);

		\node[label=above:$n_0+2d$] (n2t) at (6, 2){};
		\node (n2b) at (6, -2){};
		\draw (n2t) -- (n2b);

		\node[label=above:$n_0+3d$] (n3t) at (8, 2){};
		\node (n3b) at (8, -2){};
		\draw (n3t) -- (n3b);

		\node[label=above:$n_0+4d$] (n4t) at (10, 2){};
		\node (n4b) at (10, -2){};
		\draw (n4t) -- (n4b);

		% f_0
		\node[label=left:$f_d$] at (0, 1.5){};
		\draw[func] (0, 1.5) to [bend left=10] (2, 1.5);
		\draw[func] (2, 1.5) to [bend left=10] (4, 1.5);

		% f_1
		\node[label=left:$f_{2d}$] at (0, 0.5){};
		\draw[func] (0, 0.5) to [bend left=10] (4, 0.5);
		\draw[func] (2, 0.5) to [bend left=10] (6, 0.5);

		% f_2
		\node[label=left:$f_{3d}$] at (0, -0.5){};
		\draw[func] (0, -0.47) to [bend left=10] (6, -0.47);
		\draw[func] (2, -0.53) to [bend left=10] (8, -0.53);

		% f_3
		\node[label=left:$f_{4d}$] at (0, -1.5){};
		\draw[func] (0, -1.47) to [bend left=10] (8, -1.47);
		\draw[func] (2, -1.53) to [bend left=10] (10, -1.53);
	\end{tikzpicture}
	\caption{Graphical representation of the proof of proposition \ref{ch3:th:ne-sum-nonexsistence-inf}}
	\label{ch4:fig:ne-sum-inf-sketch}
\end{figure*}

Another example are rational or real numbers, with sums or products, as shown for instance in this example
\begin{example}
	Take $C = \mathbb{Q} \setminus \{ 0 \}$ and
	\[
	F = \{ \lambda x. x \cdot q \svert q \in \mathbb{Q} \setminus \{ 0 \} \}
	\]
	The family is highly surjective since $P(c) = \mathbb{Q} \setminus \{ 0 \}$ for all $c$, and all these functions are invertible, hence injective.
\end{example}

An interesting observation about the proof is that we used injectivity of $f$ only to show that $c_{n+1} \neq c_i$, so any other condition that allows us to do so is a fine alternative. As an example, we present here the possibility that $f$ is acyclic instead of injective.
\begin{definition}[Acyclic function]
	Given a function $f$ from $C$ in itself we say that it's \textit{acyclic} if, for any finite sequence $c_0, c_1, \dots c_n$ of elements of $C$ of any length, it doesn't happen that
	\[
	f(c_0) = c_1, f(c_1) = c_2, \dots f(c_n) = c_0
	\]

	Is this holds for all sequences of length at least $2$, we say $f$ is \textit{almost acyclic}.
\end{definition}
If $f$ is acyclic the theorem holds: if for some $0 \le j \le n$ it were $c_{n+1} = c_j$, we would incur in the contradiction that $f$ has the cycle
\[
f(c_j) = c_{j+1}, \dots, f(c_n) = c_{n+1} = c_j
\]

However acyclicness is quite restrictive because it also considers sequences of length $1$, that means that $f$ can't have fixpoints. Almost acyclicness is useful exactly for this, but it's not enough on its own.
In particular, we can require almost acyclicness to functions in $F$ if we're also able to guarantee that $f(c_n) = c_{n+1} \neq c_n$, because for $0 \le j \le n - 1$ the same proof as above is still correct. A possible condition to enforce this is
\[
\forall c \in C.\ f(c) \neq c \implies f(f(c)) \neq f(c)
\]
This condition is enough since all $c_n$ are the image of something through $f$: for $n = 0$, $f(\bar{c})= c_0 \neq \bar{c}$, and for $n > 0$, $f(c_{n-1}) = c_n \neq c_{n-1}$.
This condition could be equivalently restated as any non-fixpoint of $f$ can't be mapped to a fixpoint, that is
\[
f(C \setminus \fix(f)) \subseteq C \setminus \fix(f)
\]
This condition is still restrictive, but is less so than acyclicness, that prevents fixpoints to exist at all.
Theorem \ref{ch4:th:non-empt-res-local-basic} could hence be generalized as
\begin{theorem}\label{ch4:th:non-empt-res-local}
	Let $F$ be an highly surjective function family from $C$ in itself such that all functions $f \in F$ satisfies at least one of the following conditions:
	\begin{itemize}
		\item $f$ is injective
		\item $f$ is acyclic
		\item $f$ is almost acyclic and $f(C \setminus \fix(f)) \subseteq C \setminus \fix(f)$
	\end{itemize}
	Assume also that $R$ isn't empty. Then $A$ can't be non emptying for all $f \in F$.
\end{theorem}

As an example of this more general version, we propose floating-point numbers and multiplications.
\begin{example}\label{ch4:ex:fp-numbers-local}
	Fix as concrete domain $C$ the set $\mathcal{F_+}$ of strictly positive floating-point numbers that can be represented with a fixed number of significant digits, say $t$ bits, but with an arbitrary precision exponent. We make this choice in order to preserve characteristics of floating-point arithmetic but to have an infinite domain; a finite number of bits for exponents too would require a theorem for finite domains. We'll discuss the issues finiteness introduce in the last section of this chapter. We limit ourselves to positive numbers since multiplications don't change signs, a discussion considering also negative numbers is completely analogous but takes twice as long to handle details of sign changes.

	Let $\cdot$ and $\odot$ denote respectively real product and its floating point approximation, and consider the function family
	\[
	F = \{ \lambda x . x \odot y \svert y \in \mathcal{F_+} \}
	\]

	We now show that $F$ meets the hypothesis of the theorem. We refer the reader to appendix \ref{appA:fp-numbers} for details about floating point numbers to keep this example concise.
	The function family is highly surjective since, fixed $x = c \cdot 2^q$, we have that for all $n \ge 0$ the number
	$x \cdot 2^{-n} = c \cdot 2^{q-n}$ is in $\mathcal{F_+}$ and
	\[
	(x \cdot 2^{-n}) \odot (1 \cdot 2^{n}) = (x \odot 1) \cdot 2^{-n+n} = x
	\]
	hence $P(x) \supseteq \{ 1 \cdot 2^{-n} \svert n \ge 0 \}$ is infinite.
	For the second condition, if $y = 1 \cdot 2^{0}$ we have that the function $\lambda x. x \odot y$ is the identity, hence injective. So assume that $y > 1$ (the case $y < 1$ is analogous but for the direction of inequalities), and let us show that $\lambda x. x \odot y$ is acyclic. Assume by contradiction it has a cycle $f(x_0) = x_1, f(x_1) = x_2, \dots, f(x_n) = x_0$. By monotonicity of $\odot$ we have
	\[
	f(x) = x \odot y \ge x \odot 1 = x
	\]
	and then
	\[
	x_0 \le f(x_0) = x_1 \le f(x_1) = x_2 \le \dots \le x_n \le f(x_n) = x_0
	\]
	thus that all the elements of the cycle are equal, in particular $f(x_0) = x_0$. However, if $y \neq 1$ the product $x \odot y \neq x$, so $x_0$ can't be a fixpoint.
	This family meets hypothesis of theorem \ref{ch4:th:non-empt-res-local}, hence no abstract domain on floating point numbers can be non emptying for all multiplications.

	Observe that theorem \ref{ch4:th:non-empt-res-local-basic} wasn't enough to prove this result, since in general multiplication by a constant are not injective because of approximations.
\end{example}

\section{Global result}
The second result we propose is instead more ``global", in the sense that it requires conditions on $F$ as a whole, and not on each $f$ independently.

\begin{theorem}\label{ch4:th:non-empt-res-global}
	Let $F$ be a family of functions from $C$ in itself such that
	\begin{itemize}
		\item $F$ is highly surjective
		\item for all pair of elements $c, d \in C$ there exists at most a finite amount of $f \in F$ such that $f(d) = c$
		\item for all pair of an element $c \in C$ and a function $f \in F$, there exists at most a finite amount of elements $d \in C$ such that $f(d) = c$
	\end{itemize}
	Assume also that $R$ isn't empty. Then $A$ can't be non emptying for all $f \in F$.
\end{theorem}

The idea of the proof is that all these finiteness requirements makes it impossible to build enough $\bar{c}$ for which there exists $f_{\bar{c}}$ that maps them into $c_0$ (ie. $\bar{c} \in P(c_0)$), contradicting the hypothesis that $F$ is highly surjective. This may seem a little contradictory on its own (after all it is us that are requiring $F$ to satisfy all those conditions), but actually it is not because the proof also involves finiteness of $R$ and $R(c_0)$, that are enforced by the abstract domain.

The actual proof follows this idea in the opposite direction: starts from the (infinite) set $P(c_0)$ of $\bar{c}$ and propagates its infiniteness down to $R$.

\begin{proof}
	Assume by contradiction that $A$ is non emptying for all $f \in F$. By hypothesis, $R$ isn't empty and thus we can take a $c_0 \in R$.

	Since $F$ is an highly surjective family, $P(c_0)$ is infinite. Using lemma \ref{ch3:th:R-S-bound-integer-inf} to say that $R(c_0)$ is finite we can say that
	\begin{align*}
		E &= \{ \bar{c} \in C \svert \bar{c} \notin R(c_0), \exists f_{\bar{c}} \in F\ .\ f_{\bar{c}}(\bar{c}) = c_0 \} \\
		&= P(c_0) \setminus R(c_0)
	\end{align*}
	is infinite.

	Now fix a function $f \in F$, and let $J(f)$ be the set of $\bar{c}$ for which $f$ is exactly $f_{\bar{c}}$:
	\[
	J(f) = \{ \bar{c} \in C \setminus R(c_0) \svert f = f_{\bar{c}} \}
	\]

	Hence for all $\bar{c} \in J(f)$ we have $f(\bar{c}) = c_0$. By the third condition on $F$, this can be true for at most a finite amount of $\bar{c}$, that is $J(f)$ is finite.

	Now let $G$ be the set of functions in $F$ that are $f_{\bar{c}}$ for some $\bar{c} \in E$:
	\[
	G = \{ f \in F \svert \exists \bar{c} \in E\ .\ f = f_{\bar{c}} \}
	\]
	Clearly
	\[
	E = \bigcup\limits_{f \in G} J(f)
	\]
	But we know that $E$ is infinite while all $J(f)$ are finite, so $G$ must be infinite too.

	By lemma \ref{ch3:th:f-non-repr-pair}, for all $\bar{c} \in E$ we have $f_{\bar{c}}(c_0)$ is representable. This can be equivalently restated saying that for all $f \in G$, $f(c_0)$ is representable.
	So consider the set $I$ of all possible images of $c_0$ through functions in $G$:
	\[
	I = \{ f(c_0) \svert f \in G \}
	\]
	This set is a subset of $R$ because all its elements are representable.

	Clearly
	\[
	G = \bigcup\limits_{d \in I} \{ f \in G \svert f(c_0) = d \}
	\]
	But we know that $G$ is infinite and, for any $d \in C$, by the second condition on $F$ we have that
	\[
	\{ f \in F \svert f(c_0) = d \}
	\]
	is finite, and this is a superset of $\{ f \in G \svert f(c_0) = d \}$. So $I$ must be infinite too.

	However, this yields the desired contradiction: $I$ is infinite and is a subset of $R$, that is finite.
\end{proof}

As an example of such a family of functions we again propose floating-point numbers with multiplications:
\begin{example}\label{ch4:ex:fp-numbers-global}
	Take $C = \mathcal{F} \setminus \{ 0 \}$ the set of non-zero floating-point numbers with $t$ bits significants, one bit sign and arbitrary precision exponents, and
	\[
	F = \{ \lambda x . x \odot y \svert y \in \mathcal{F} \setminus \{ 0 \} \}
	\]

	A straightforward adaptation of the argument of example \ref{ch4:ex:fp-numbers-local} (to take into account signs) shows that this family is highly surjective.
	Fixed two floating-point numbers $x, y$, we have that $y = f(x) = x \odot z$ only if
	\[
	\left\lvert \frac{y - (x \cdot z)}{x \cdot z} \right\rvert < \macheps
	\]
	that is
	\[
	\left\lvert\frac{y}{x}\right\rvert \frac{1}{1+\macheps} < \abs{z} < \left\lvert\frac{y}{x}\right\rvert \frac{1}{1-\macheps}
	\]
	This is a bounded interval since $x \neq 0$, and hence contains only a finite amount of floating-point numbers.
	Conversely, fixed a floating point $y$ and a function $f(x) = x \odot z$, we have that $y = x \odot z$ only if the same condition as above holds, that solved in $x$ becomes
	\[
	\left\lvert\frac{y}{z}\right\rvert \frac{1}{1+\macheps} < \abs{x} < \left\lvert\frac{y}{z}\right\rvert \frac{1}{1-\macheps}
	\]
	Again since $z \neq 0$ this is a bounded interval, thus proving the finiteness of the amount of floating-point $x$ that satisfies it.

	So, by means of theorem \ref{ch4:th:non-empt-res-global} above, we proved again that no abstract domain on floating-point numbers can be non emptying for all multiplications.
\end{example}

\section{Limitations}
We began with theorem \ref{ch4:th:non-empt-res-local-basic}, that required all functions in $F$ to be injective, and then we tried to relax that requirement, either asking other properties on each individual function or adding conditions on $F$ as a whole.
A natural question at this point is then what can be done to weaken the high surjectivity hypothesis. The answer is nothing.

The requirement that the function family $F$ is highly surjective is somewhat global: we require that \textit{all} possible $c$ has infinitely many preimages.
We use this condition in the proofs to apply lemma \ref{ch3:th:f-non-repr-pair} and get that some elements can be mapped to the only known representable elements. We need this condition for all possible choices of $c$ because first we fix the function family we want to analyse, then we can pick the abstract domain, so the ``initial" representable element $c$.
Thinking of this as a game, player one fixes the function family $F$ and wants to show that no abstract domain is able to analyse it, so player two thinks of a counterexample \textit{with $F$ in mind}, that is they can carefully craft it around the specific choice of $F$. This leads to universal quantifiers over elements of $C$: in fact, if there is even a single $c_0$ for which the condition doesn't hold, player two can actually construct such counterexample starting from that specific value, as showed in the following proposition.
\begin{prop}\label{ch4:th:no-higly-onto-domain-construction}
	For any fixed family $F$ of functions from $C$ in itself that is not highly surjective, there exists an abstract domain $A_F$ such that:
	\begin{itemize}
		\item $A_F$ is finite
		\item all functions $f \in F$ are non emptying in $A_F$
	\end{itemize}
\end{prop}
\begin{proof}
	Since $F$ is not highly surjective, there exists $c_0 \in C$ such that $P(c_0)$ is finite. We then define $A_F$ as follows.
	The only element of $C$ representable on its own is $c_0$ itself, ie. $R = \{ c_0 \}$.
	A pair of elements of $C$ is representable if and only if one of its elements is $c_0$ and the other is in $P(c_0)$. This also means that $R(c_0) = P(c_0)$.
	Subsets of $C$ with at least three elements are representable if and only if they are unions of representable pairs.
	The complete definition of $A_F$ is then
	\[
	A_F = \{ \emptyset, \{ c_0 \} \} \cup \{ \{ c_0 \} \cup T \svert T \subseteq P(c_0) \}
	\]
	$A_F$ is an opposite Moore family with respect to $\pow(C)$: it contains the minimal element, that is $\emptyset$, and is closed by union, that are lubs. Hence $A_F$ is an under-approximation abstract domain by means of proposition \ref{ch2:th:under-gi-moore-family}.
	Moreover, since $R(c_0) = P(c_0)$ is finite, we get that $A_F$ is finite too:
	\[
	\abs{A_F} = 2 + 2^{\abs{P(c_0)}}
	\]

	Now we want to show that an arbitrary $f$ in $F$ is non emptying in $A_F$.
	We first observe that a subset $S \subseteq C$ is such that $\alpha(S) \neq \emptyset$ if and only if $c_0 \in S$. Suppose that $c_0 \in S$, then
	\[
	\alpha(S) \supseteq \alpha(\{ c_0 \}) = \{ c_0 \} \supset \emptyset
	\]
	Conversely, suppose that $\alpha(S) \neq \emptyset$. Since all elements of $A_F$ but the empty set contains $c_0$, by correctness we have
	\[
	c_0 \in \alpha(S) \subseteq S
	\]

	So fix now $S \subseteq C$ an element of the concrete domain, and assume that both $\alpha(S) \neq \emptyset$ and $\alpha(f(S)) \neq \emptyset$.
	These two assumptions are equivalent to $c_0 \in S$ and $c_0 \in f(S)$ respectively, and the latter can be equivalently rewritten as $\exists d \in S\ .\ f(d) = c_0$. But by definition of $A_F$ we know this is equivalent to $d \in P(c_0) = R(c_0)$.
	Hence
	\begin{align*}
		&S \supseteq \{ c_0, d \} \\
		\implies& \alpha(S) \supseteq \alpha(\{ c_0, d \}) = \{ c_0, d \} \\
		\implies& f(\alpha(S)) \supseteq f(\{ c_0, d \}) \supseteq \{ f(d) \} = \{ c_0 \} \\
		\implies& f^{\flat}(\alpha(S)) = \alpha(f(\alpha(S))) \supseteq \alpha(\{ c_0 \}) = \{ c_0 \}
	\end{align*}
	where in the second line we used that $\alpha(\{ c_0, d \}) = \{ c_0, d \}$ because $d \in R(c_0)$ and in the third the fact that $f(d) = c_0$.
	The last line implies $f^{\flat}(\alpha(S)) \neq \emptyset$, so $f$ is non emptying in $A_F$.
\end{proof}

We now show a simple example of the construction used in the proof.
\begin{example}
	Fix the pair of functions $f(x) = x - 1$ and $g(x) = x - 2$ on $\setZ$, and let us build an under-approximating abstract domain for which these functions are non emptying. Following the proof of the previous proposition, we need an integer $n_0$ such that only a finite amount of integers can be mapped into it using either $f$ or $g$. Clearly any integer is fine, so let us fix $n_0 = 0$.

	The set $P(0)$ of integers that can be mapped into $0$ is simply $P(0) = \{ 1, 2 \}$. The abstract domain is then
	\[
	A_F = \{ \emptyset, \{ 0 \}, \{ 0, 1 \}, \{ 0, 2 \}, \{ 0, 1, 2 \} \}
	\]
	Both $f$ and $g$ are non emptying in $A_F$. A set $S$ isn't abstracted to $\emptyset$ if and only if it contains $0$, so fix one that does.
	For $f(S)$ not to be abstracted to $\emptyset$ we need also it to contain $0$, that means $1 \in S$. So
	\begin{align*}
		f^{\flat}(\alpha(S)) &= \alpha(f(\alpha(S))) \\
		&\supseteq \alpha(f(\alpha(\{ 0, 1 \}))) \\
		&= \alpha(f(\{ 0, 1 \})) \\
		&= \alpha(\{ -1, 0 \}) = \{ 0 \}
	\end{align*}
	The check for $g$ is analogous.
\end{example}
It's also interesting to note that the proof of this proposition is somewhat reminiscent of example \ref{ch3:ex:ne-not-complete}. The reason is that both in that example and in this proposition, all elements of the abstract domain but the empty set share a common element, $0$ in the example and $c_0$ here.

This proposition gives us one limit of approaches based on non emptying functions to show non existence of under-approximation abstract domains: whatever we do, we must fix enough functions to have high surjectivity. This in particular means these approaches are ill suited to prove results where we focus on a single function.

Moving onward along this line of thought, we can straightforwardly generalize the proposition just presented to an arbitrary subset $S \subseteq C$ with a finite amount of preimages.
Definition of preimages of an element (see definition \ref{ch4:def:highly-onto-func-family}) can be lifted to an arbitrary subset $S$ of $C$ as
\[
P(S) = \{ T \subseteq C \svert \exists f \in F. f(T) = S \}
\]
Do note that in this definition we require that a single function $f$ maps the whole $T$ to $S$.
\begin{prop}\label{ch4:th:existence-finte-backward}
	Let $F$ be a family of functions from $\pow(C)$ in itself, and assume there is a set $S_0 \subseteq C$ such that $P(S_0)$ is finite. Then there exists a finite abstract domain $A_F$ such that all functions $f \in F$ are non emptying in $A_F$.
\end{prop}
\begin{proof}
	Since the proof is very similar to that of proposition \ref{ch4:th:no-higly-onto-domain-construction} above, we gloss over some details.

	First, we define a \textit{basis} of the abstract domain as
	\[
	B_F = \{ S_0 \} \cup \{ S_0 \cup S \svert S \in P(S_0) \}
	\]
	and then consider its union closure
	\[
	A_F = \left\lbrace \bigcup\limits_{T \in \Gamma} T \svert \Gamma \subseteq B_F \right\rbrace
	\]
	This is a dual Moore family and hence is an under-approximation abstract domain for $\pow(C)$, and is finite because
	\[
	\abs{A_F} \le \abs{\pow(B_F)}
	\]
	and
	\[
	\abs{B_F} = \abs{\pow(P(S_0))}
	\]
	with $P(S_0)$ finite by hypothesis.

	Again we observe that a subset $T \subseteq C$ is such that $\alpha(T) \neq \emptyset$ if and only if $S_0 \subseteq T$ because all elements of the abstract domain but the empty set contains $S_0$. Then the proof proceeds as above: fix $f \in F$ and $T \subseteq C$ such that $\alpha(T) \neq \emptyset$ and $\alpha(f(T)) \neq \emptyset$, that in turn are equivalent to $S_0 \subseteq T$ and $\exists S \subseteq T. f(S) = S_0$. Then by definition of $A_F$ this means $S_0 \cup S \in A_F$, so
	\begin{align*}
		&T \supseteq S_0 \cup S \\
		\implies& \alpha(T) \supseteq \alpha(S_0 \cup S) = S_0 \cup S \\
		\implies& f(\alpha(T)) \supseteq f(S_0 \cup S) \supseteq f(S) = S_0 \\
		\implies& f^{\flat}(\alpha(T)) = \alpha(f(\alpha(T))) \supseteq \alpha(S_0) = S_0
	\end{align*}
	that is $f$ is non emptying.
\end{proof}

\begin{example}
	Fix the concrete domain $C$ as the set of all lists of finite length over a finite, non-empty alphabet $\Gamma$, that is $C = \Gamma^{*}$.
	For $\alpha \in \Gamma^*$ a finite string, let
	\[
	\concat_{\alpha}(\beta) = \alpha \beta
	\]
	the function that prepend $\alpha$ to its argument.

	The family
	\[
	F = \{ \concat_{\alpha} \svert \alpha \in \Gamma^* \}
	\]
	is not highly surjective, because fixed a string $\gamma$ only its prefixes can be mapped to it by a function in $F$, and since the number of prefixes is exactly the length of the string they are a finite amount.
	Hence we can define an under-approximation abstract domain for which all these functions are non emptying by means of proposition \ref{ch4:th:existence-finte-backward}.

	Actually there is one such domain that is very simple to describe. If $\epsilon$ is the empty list, the abstract domain where that is only representable element
	\[
	A_F = \{ \emptyset, \{ \epsilon \} \}
	\]
	is the desired domain. We could prove explicitly that this is non emptying for all $\drop_n$, but instead we rely again on proposition \ref{ch4:th:existence-finte-backward} just noting that this is the domain we get from that proposition with $S_0 = \{ \epsilon \}$.
\end{example}

This proposition can be intuitively interpreted as saying that if there is a (concrete) element from which ``going backward along $F$" results in a finite amount of elements then we can define an abstract domain around that specific element for which all functions in $F$ are non emptying.
A natural dual of this statement could consider what happens when ``going forward along $F$", and it turns out that the situation is quite similar.
For a subset $S \subseteq C$, let $I(S)$ be the set of all images of $S$ through functions of $F$ to $S$:
\[
I(S) = \{ f(S) \svert f \in F \}
\]
This intuitively correspond to ``go forward along $F$", and this definition is exactly dual to $P(S)$. With this, we can then prove a statement akin to the previous one.
\begin{prop}\label{ch4:th:existence-finte-forward}
	Let $F$ be a family of functions from $\pow(C)$ in itself that don't diverge (ie. if $S \neq \emptyset$ then $f(S) \neq \emptyset$), and assume there is a non empty set $S_0 \subseteq C$ such that $I(S_0)$ is finite. Then there exists a finite abstract domain $A_F$ such that all functions $f \in F$ are non emptying in $A_F$.
\end{prop}
\begin{proof}
	Define a basis of the abstract domain
	\[
	B_F = \{ S_0 \} \cup \{ S_0 \cup S \svert S \in I(S_0) \}
	\]
	and consider its union closure
	\[
	A_F = \left\lbrace \bigcup\limits_{T \in \Gamma} T \svert \Gamma \subseteq B_F \right\rbrace
	\]
	Again this is a correct finite under-approximation abstract domain for $\pow(C)$ satisfying that $\alpha(T) \neq \emptyset$ if and only if $S_0 \subseteq T$ (this can be shown in the exact same way as in the proof of the previous proposition \ref{ch4:th:existence-finte-backward}).

	Taken an arbitrary $f \in F$ let us show that it's non emptying. Fix a $T \subseteq C$ such that $\alpha(T) \neq \emptyset$. This equivalently means that $S_0 \subseteq T$, so
	\begin{align*}
		& \alpha(T) \supseteq \alpha(S_0) = S_0 \\
		\implies& f(\alpha(T)) \supseteq f(S_0) \\
		\implies& f^{\flat}(\alpha(T)) = \alpha(f(\alpha(T))) \supseteq \alpha(f(S_0))
	\end{align*}
	But $f(S_0) \in B_F$, so $\alpha(f(S_0)) = f(S_0) \neq \emptyset$ by the hypothesis that $f$ doesn't diverge, and so $f^{\flat}(\alpha(T)) \neq \emptyset$, that is $f$ is non emptying.
\end{proof}
In the proof we needed the hypothesis that $f$ doesn't diverge because otherwise we could have $f(S_0) = \emptyset$. However we don't believe this to be a very restrictive hypothesis because these theorems are intended to be applied when $F$ is a family of basic transfer functions, that seldom introduce divergence: in programming languages this is often caused by control-flow constructs.
Another important observation is that we didn't use the hypothesis that $\alpha(f(T)) \neq \emptyset$: this is always the case if $\alpha(T) \neq \emptyset$ because $\alpha(f(T)) \supseteq \alpha(f(S_0)) = f(S_0)$. While it may seem counterintuitive that we didn't use one of the hypothesis, the reason is that the abstract domain $A_F$ is so crafted around $F$ that this condition becomes vacuous.

\begin{example}
	Fix again $C = \Gamma^{*}$, but this time consider functions $\drop_n : \Gamma^* \rightarrow \Gamma^*$ that, taken a list, drop its first $n$ elements and return the resulting list. If the input list is shorter than $n$, the output of $\drop_n$ is the empty list $\epsilon$.

	Consider the function family
	\[
	F = \{ \drop_n \svert n \in \setN \}
	\]
	This is highly surjective since, for any fixed list $\alpha \in \Gamma^*$ and any $n$, we can consider the list obtained prefixing to $\alpha$ any character of $\Gamma$ exactly $n$ times, and map this list to $\alpha$ with $\drop_n$.
	However, if we consider
	\[
	I(\{ \alpha \}) = \{ \{ \drop_n(\alpha) \} \svert n \in \setN \}
	\]
	this is clearly finite since it's the set of all tails of $\alpha$, and hence by proposition \ref{ch4:th:existence-finte-forward} we can define an under-approximation abstract domain such that all functions $\drop_n$ are non emptying.

	Again, one such domain is very easy:
	\[
	A_F = \{ \emptyset, \{ \epsilon \} \}
	\]
	and is the domain obtained from proposition \ref{ch4:th:existence-finte-forward} if we consider $S_0 = \{ \epsilon \}$, that indeed satisfies $I(S_0) = \{ \{ \epsilon \} \}$ finite.
\end{example}

It is interesting to note that the very same abstract domain is a counterexample for both family of functions. This domain is a power set of elements of $C$, and in particular it contains the ``boundary" of $C$. Here boundary must be intended with respect to the function family at hand: either a set in which you can't enter (the ``initial boundary", as in the example of $\concat_{\alpha}$) or a set from which you can't exit (the ``final boundary", as in the example of $\drop_n$).
This line of reasoning is actually quite general: every time a concrete domain has some sort of boundary, often natural operations on that domain goes either towards or away from that boundary, so that any element has a finite ``distance" (in terms of functions applications) from it, making one of these two proposition applicable.
For instance, consider positive integers with multiplications and divisions (rounded down). In this case the boundary is $0$: multiplications go away from it while divisions go towards it. It's easy to observe that multiplications satisfy proposition \ref{ch4:th:existence-finte-backward} because any number has a finite amount of preimages, while divisions satisfy proposition \ref{ch4:th:existence-finte-forward} because any number has finite amount of (iterate) images.

A possible solution to this could be to consider \textit{together} functions that goes toward and away from the boundary: for instance, put together $\drop_n$ and $\concat_{\alpha}$. However, this doesn't solve the issue.
\begin{example}
	Let $C = \Gamma^*$, and
	\[
	F = \{ \drop_n \svert n \in \setN \} \cup \{ \concat_{\alpha} \svert \alpha \in \Gamma^* \}
	\]
	Consider the under-approximation abstract domain
	\[
	A_F = \{ \emptyset, \{ \epsilon \} \}
	\]
	Then all functions in $F$ are non emptying in $A_F$.

	The proof is carried over separately for the two sets, and proceeds as in proposition \ref{ch4:th:existence-finte-backward} for $\concat_{\alpha}$ and as in \ref{ch4:th:existence-finte-forward} for $\drop_n$.
\end{example}
In general, we can partition functions in $F$ in those that enter the boundary and those that exit, and apply separately the two propositions to get that the abstract domain is non emptying for all of them. So we need a single function that is able to both enter and exit the boundary at the same time, and this should be true for all possible finite boundaries.

\begin{theorem}\label{ch4:th:existence-finite-backward-forward}
	Let $F$ be a family of functions from $\pow(C)$ in itself. Assume there is a non empty set $S_0 \in \pow(C)$ and $F$ can be partitioned in two sets $F_{>}$ and $F_{<}$ such that
	\begin{itemize}
		\item $P(S_0)$ computed with respect to the function family $F_{<}$ is finite
		\item $I(S_0)$ computed with respect to the function family $F_{>}$ is finite and all functions in  $F_{>}$ don't diverge
	\end{itemize}
	Then there exists a finite abstract domain $A_F$ such that all functions $f \in F$ are non emptying in $A_F$.
\end{theorem}
\begin{proof}
	Define the basis of the abstract domain
	\[
	B_F = \{ S_0 \cup S \svert S \in P(S_0) \} \cup \{ S_0 \cup S \svert S \in I(S_0) \}
	\]
	and then consider its union closure
	\[
	A_F = \left\lbrace \bigcup\limits_{T \in \Gamma} T \svert \Gamma \subseteq B_F \right\rbrace
	\]
	As before, this is a finite under-approximation domain for $\pow(C)$ and satisfies that	$\alpha(T) \neq \emptyset$ if and only if $S_0 \subseteq T$.

	For $f \in F_{<}$ the proof is carried over as in proposition \ref{ch4:th:existence-finte-backward}, while for $f \in F_{>}$ as in proposition \ref{ch4:th:existence-finte-forward}. Then all functions in $F$ are non emptying.
\end{proof}

Even thought boundaries are common in practice, it's not always the case that \textit{all} values of the concrete domain can reach them. An interesting example can be found in infinite lists.
\begin{example}\label{ch4:ex:infinite-lists-fix-c0}
	Let $\Gamma$ be a finite alphabet, and let $\Gamma^{\setN}$ be the set of infinite lists over that alphabet. An infinite list may be thought of as an head, an element of the alphabet, followed by a tail, another infinite list.
	Fix $C = \Gamma^{\setN}$ and
	\[
	F = \{ \drop_n \svert n \in \setN \}
	\]

	This domain has a final boundary with respect to this family of functions $F$: the set of constant list, that are a single character repeated infinitely many times.
	This serves also as initial boundary for $\concat$ operations. Actually the abstract domain made as the power set of the set of all constant list is finite (since $\Gamma$ is) and all $\drop$ and $\concat$ are non emptying in it.

	An analogous argument can be made for infinite lists with a period of $2$, of $3$ and so on, hence any of these sets define a different boundary.
	However, there are infinite lists that aren't periodic. Such lists can be characterized by having all different tails: if they had two equal, that would be a periodicity. Since applying $\drop_n$ to any of these lists yields again a non periodic one, they can't be mapped into a boundary by any function in $F$.
	So consider now the proofs of the local results, theorem \ref{ch4:th:non-empt-res-local}. If we assume that the initial representable element $c_0$ is a non periodic list, we can follow the same proof since this family is actually highly surjective. The missing point to conclude the proof is to show that all $c_n$ are different since we don't have neither injectivity nor acycliness of $\drop_n$.
	However, observe that, if we restrict ourselves to non periodic lists, $\drop_n$ is actually acyclic, and all $c_n$ are non periodic lists because they are images of the non periodic list $c_{n-1}$ through a function $\drop_n$.
	Formally, we can show it observing that if $c_n = c_m$ with $n < m$ we would have that the $c_m$ is a tail of $c_n$ and is equal to the whole list $c_n$, that hence would be periodic, contradiction since $c_0$ isn't periodic and the image of a non periodic list through a function $\drop_n$ is still non periodic.
\end{example}
In this example, we can partition the set of infinite lists $\Gamma^{\setN}$ depending on the length of the period of each element. $\drop_n$ and $\concat_{\alpha}$ doesn't change this value, hence they operate separately on each one of the partitions. All partitions corresponding to a finite length period have a finite boundary, that are the possible periods of that length, without any prefix. However, the partition corresponding to infinite length period, or non periodic lists, doesn't have a boundary and hence we can apply theorem \ref{ch4:th:non-empt-res-local} to it.

\section{Finite domains}
All the discussion in this chapter but the theorem about non relational domains require $C$ to be infinite. An interesting question is whether the two results presented can be reproduced when it finite instead, but this doesn't seem likely.

For the local result \ref{ch4:th:non-empt-res-local}, we prove non existence of the abstract domain defining an infinite sequence of representable elements. To do this with a finite $C$, if $N = \abs{C}$, we would like to resort to lemma \ref{ch3:th:R-S-bound-integer-fin} to say that $\abs{R} = O(\log(N))$ and show that the sequence has length $\omega(\log(N))$. However, the straightforward generalization of the proof doesn't yield this result. It proceed as follows: we consider the initial $NR(c_0)$ of size
\[
\abs{NR(c_0)} = \abs{C} - \abs{R(c_0)} = N - O(\log(N)) = \Theta(N)
\]
Then, when we pick $c_{n+1}$ we take an element of $\{ f_{\bar{c}(c_n)} \svert \bar{c} \in E_n \}$ that maximizes the cardinality of
\[
\{\ \bar{c} \in E_n \svert f_{\bar{c}}(c_n) = c_{n+1} \}
\]
Since there are at most $\abs{R} = O(\log(N))$ possible choices for $c_{n+1}$, this in the worst case is $\abs{E_n} / O(\log(N))$. However, this in the end is compatible with the cardinality of $R$: if we assume the sequence has length $m$, this have only to satisfy
\[
\frac{\Theta(N)}{O(\log(N))^m} = O(\log(N))
\]
since each new element of the sequence chops a logarithmic factor off of the cardinality of $E_n$, and $\abs{E_0} = \Theta(\abs{NR(c_0)}) = \Theta(N)$. But this relation holds for $m = O(\log(N)) = O(\abs{R})$, so there is no contradiction.
Also other possible generalizations incur in the same issue, that basically boils down to the fact that arbitrary combination of finite numbers is finite while arbitrary combination of logarithmic factors is not $O(N)$.

For the global result \ref{ch4:th:non-empt-res-global} there isn't a single way to restate it for a finite domain. We could constrain both the number of functions $f$ that maps a given $c$ to a given $d$ and the number of $d$ that are mapped by a given $f$ to a given $c$ to be logarithmic, but again this is not enough because it would end up with
\[
O(\log(N))^{O(\log(N))} = \Omega(N)
\]
not giving the desired contradiction.

The very same definition of highly surjective family needs to be rewritten. If we perform the construction of proposition \ref{ch4:th:no-higly-onto-domain-construction} with a finite $C$ we discover that it is possible already if $\abs{P(c)} = O(\log(N))$; however to carry out the proofs we need much more, possibly up to $\abs{P(c)} = \Theta(N)$.

Even with all these theoretical results against a rephrasing of the theorems to the finite setting, we could still prove it in the special case of the finite domain $[-N, N]$ of integers. Of course we used the structure of both the function family and the concrete domain in the proof, but what we believe to be the key properties that allowed it are two.
First, this domain has a metric structure on it. Every time we get a new representable element, we do so with a function $f$ such that $f(\bar{n}) = n_i$ and $f(n_0) = n_{i+1}$. Combining this with the fact that $f$ preserves distances, we got that all the representable elements were not so far apart with respect to the diameter of the concrete domain, thus giving us a mean to prove that $R$ was too big.
Second, the domain is circular and hence has no boundaries. If the domain does have them we can apply propositions of the previous section to build an abstract domain around the function family. This was not the case for integers because additions overflow, so the domain has no boundaries near $-N$ and $N$.

Building on the latter of those two considerations, we present a version of the global result \ref{ch4:th:non-empt-res-global} for finite domains. To overcome the limitation of boundaries, we constrain the initial representable element $c_0$. As we did in the specific case of the integer domain $[-N; N]$, we use asymptotic notation appealing to the intuition it gives rather than its precise formalism.
\begin{theorem}\label{ch4:th:non-empt-res-finite-global}
	Let $C$ be a finite set of size $N$, and let $F$ be a family of functions from $C$ in itself. Assume there exists a concrete element $c_0 \in C$ that is representable ($c_0 \in R$) and two bound functions $k_1, k_2 : \setN \rightarrow \setN_{>0}$ such that
	\begin{itemize}
		\item for all elements $d \in C$, the number of functions $f \in F$ such that $f(c_0) = d$ is at most $k_1(N)$
		\item for all functions $f \in F$, the number of elements $d \in C$ such that $f(d) = c_0$ is at most $k_2(N)$
		\item $\abs{P(c_0)} = \omega(\log(N) \cdot k_1(N) \cdot k_2(N))$
	\end{itemize}
	Then $A$ can't be non emptying for all $f \in F$.
\end{theorem}
The idea of this proof is the same as in the infinite case. $c_0$ is the initial representable element, but in the finite setting we write hypothesis around it instead of have them global and requiring the existence of a generic representable element. The first two conditions correspond to those of the infinite case result, simply rewritten with $c_0$ in mind. The last condition binds together the two bounds $k_1$ and $k_2$ on cardinalities with the number of preimages of $c_0$, and correspond to the infinite hypothesis of high surjectivity: it only constraints the value $c_0$ because we know this is the representable value from which the proof begins. The precise relation is chosen to get the contradiction in the proof.
\begin{proof}
	By way of contradiction assume that $A$ is non emptying for all $f \in F$.

	Using lemma \ref{ch3:th:R-S-bound-integer-fin} to say that $R(c_0) = O(\log(N))$ we can say that
	\begin{align*}
		E &= \{ \bar{c} \in C \svert \bar{c} \notin R(c_0), \exists f_{\bar{c}} \in F\ .\ f_{\bar{c}}(\bar{c}) = c_0 \} \\
		&= P(c_0) \setminus R(c_0)
	\end{align*}
	has cardinality
	\[
	\abs{E} \ge \abs{P(c_0)} - \abs{R(c_0)} = \abs{P(c_0)} - O(\log(N))
	\]
	Since by hypothesis $k_1(N), k_2(N) \ge 1$
	\[
	\abs{P(c_0)} = \omega(\log(N) \cdot k_1(N) \cdot k_2(N)) \ge \omega(\log(N))
	\]
	and so we have
	\[
	\abs{E} \ge \abs{P(c_0)} - O(\log(N)) = \Theta(\abs{P(c_0)})
	\]

	Now fix a function $f \in F$, and let $J(f)$ be the set of $\bar{c}$ for which $f$ is exactly $f_{\bar{c}}$:
	\[
	J(f) = \{ \bar{c} \in C \setminus R(c_0) \svert f = f_{\bar{c}} \}
	\]
	Hence for all $\bar{c} \in J(f)$ we have $f(\bar{c}) = c_0$. By the second hypothesis, this can be true for at most $k_2(N)$ different $\bar{c}$, that is $\abs{J(f)} \le k_2(N)$.

	Now let $G$ be the set of functions in $F$ that are $f_{\bar{c}}$ for some $\bar{c} \in E$:
	\[
	G = \{ f \in F \svert \exists \bar{c} \in E\ .\ f = f_{\bar{c}} \}
	\]
	Clearly
	\[
	E = \bigcup\limits_{f \in G} J(f)
	\]
	But we know that $\abs{E} \ge \Theta(\abs{P(c_0)})$ while all $\abs{J(f)} \le k_2$, so
	\[
	\abs{G} \ge \frac{\abs{E}}{\max\limits_{f \in G}(\abs{J(f)})} \ge \frac{\Theta(\abs{P(c_0)})}{k_2(N)}
	\]

	By lemma \ref{ch3:th:f-non-repr-pair}, for all $\bar{c} \in E$ we have $f_{\bar{c}}(c_0)$ is representable. This can be equivalently restated saying that for all $f \in G$, $f(c_0)$ is representable.
	So consider the set $I$ of all possible images of $c_0$ through functions in $G$:
	\[
	I = \{ f(c_0) \svert f \in G \}
	\]
	This set is a subset of $R$ because all its elements are representable.

	Clearly
	\[
	G = \bigcup\limits_{d \in I} \{ f \in G \svert f(c_0) = d \}
	\]
	But we know that, for any $d \in C$, by the first hypothesis we have that
	\[
	\abs{\{ f \in F \svert f(c_0) = d \}} \le k_1(N)
	\]
	and this is a superset of $\{ f \in G \svert f(c_0) = d \}$. So
	\[
	\abs{I} \ge \frac{\abs{G}}{\max\limits_{d \in I} (\abs{\{ f \in G \svert f(c_0) = d \}})} \ge \frac{\Theta(\abs{P(c_0)})}{k_2(N)} \cdot \frac{1}{k_1(N)}
	\]

	By the third hypothesis
	\[
	\abs{I} \ge \frac{\Theta(\abs{P(c_0)})}{k_2(N) \cdot  k_1(N)} = \omega(\log(N))
	\]
	but this is a contradiction because $I$ is a subset of $R$, hence
	\[
	O(\log(N)) = \abs{R} \ge \abs{I} \ge \omega(\log(N))
	\]
\end{proof}
Of course, if we verify the conditions for each value in $C$ we have that there is no under-approximation domain whenever $R$ is not empty, as we can do for integers
\begin{example}
	Let $C = \pow([-N, N])$ and
	\[
	F = \{ \lambda x. x + n (\text{modulo } 2N+1) \svert n \in [-N, N] \}
	\]

	Fixed any $n_0 \in [-N, N]$, it's easy to check that $P(n_0) = [-N, N]$ and $k_1(N) = k_2(N) = 1$. The condition
	\[
	\abs{P(n_0)} = \omega(\log(2N + 1) \cdot k_1(2N + 1) \cdot k_2(2N + 1))
	\]
	thus reduces to
	\[
	2N + 1 = \omega(\log(N))
	\]
	that is true. Hence there is no under-approximation abstract domain with a single integer $n_0$ representable, as already shown in theorem \ref{ch3:th:ne-sum-nonexsistence-fin}.
\end{example}
The example of integers has the nice property of not having boundaries, but this is seldom the case. For instance, consider floating point numbers: they overflow and underflow to special values, hence they do have boundaries. Nevertheless, if we pick a suitable initial element $c_0$ we can apply the theorem above.

\begin{example}
	Consider the finite set of non-zero floating-point numbers $C = \mathcal{F} \setminus \{ 0 \}$ with $t$ bits significants, one bit sign and $e$ bit exponents. We again refer the reader to appendix \ref{appA:fp-numbers} for details about floating point numbers to keep this example concise.
	Consider the function family
	\[
	F = \{ \lambda x . x \odot y \svert y \in \mathcal{F} \setminus \{ 0 \} \}
	\]
	of floating-point multiplications.

	As shown in example \ref{ch4:ex:fp-numbers-global}, fixed two floating-point numbers $x, y$, we have that $y = f(x) = x \odot z$ only if
	\[
	\abs{z} \in \left[ \left\lvert\frac{y}{x}\right\rvert \frac{1}{1+\macheps}, \left\lvert\frac{y}{x}\right\rvert \frac{1}{1-\macheps} \right]
	\]
	If $\macheps \le 1 / 2$ this is entirely contained in the interval
	\[
	\left[ \left\lvert\frac{y}{x}\right\rvert (1 - 2 \macheps), \left\lvert\frac{y}{x}\right\rvert (1 + 2 \macheps) \right]
	\]
	that contains at most $17$ floating point numbers if $t \ge 3$.
	Analogously, fixed $y$ and $z$ there are at most $17$ floating point numbers $x$ such that $y = f(x) = x \odot z$.

	With these two bounds, if $x_0$ has enough preimages, eg. $x_0 = 1$ so that at least about half floating point numbers have an inverse and hence are in $P(x_0)$, we can verify the last hypothesis of the theorem: if $N = \abs{C}$
	\[
	\abs{P(x_0)} = \Theta(N) = \omega(\log(N) \cdot 17 \cdot 17) = \omega(\log(N) \cdot k_1(N) \cdot k_2(N))
	\]
	Hence, by mean of theorem \ref{ch4:th:non-empt-res-finite-global}, no under-approximation abstract domain is non emptying for all multiplications.
\end{example}
